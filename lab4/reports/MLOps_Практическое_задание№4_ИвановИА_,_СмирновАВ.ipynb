{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Набор генерируемых данных\n",
        "\n",
        "В рамках настоящего задания продолжаем тематику нашего сквозного проекта с использованием данных по стоимости и длительности перевозок грузов из одной точки (Гуанджоу, Китай) в другую (Москва, Россия)."
      ],
      "metadata": {
        "id": "N-MlfPXTlapO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Создание файла data_creation.py\n",
        "\n",
        "data_creation.py - python-скрипт, который создает набор данных о перевозках грузов из одной точки (Гуанджоу, Китай) в другую (Москва, Россия) и обратно.\n"
      ],
      "metadata": {
        "id": "0jbjkDFhSX7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Добавляем новый столбец - departure_city (\"город отправления\")\n",
        "cities = ['Guangzhou', 'Moscow']\n",
        "departure_city = np.random.choice(cities, size=1000)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Добавляем новый столбец - forwarder (\"экспедитор\")\n",
        "forwarder = ['Guangzhou_forwarder', 'Moscow_forwarder']\n",
        "freight_forwarder = np.random.choice(forwarder, size=1000)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Создание датасета\n",
        "data = pd.DataFrame({\n",
        "    'price': np.abs(np.random.normal(650000, 100000, 1000)),\n",
        "    'delivery_time': np.abs(np.random.normal(25, 10, 1000)),\n",
        "    'number_of_transit_nodes': np.abs(np.round(np.random.normal(3, 2, 1000))),\n",
        "    'departure_city': departure_city,\n",
        "    'freight_forwarder': freight_forwarder\n",
        "})\n",
        "\n",
        "# Добавление случайных пропусков в столбце 'price'\n",
        "num_missing = 5  # Количество пропусков для добавления\n",
        "missing_indices = np.random.choice(data.index, size=num_missing, replace=False)\n",
        "data.loc[missing_indices, 'price'] = np.nan\n",
        "\n",
        "# Сохранение данных в файл\n",
        "data.to_csv('datasets_storage/data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "3JVtyeKEQ9OI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Создание файла data_preprocessing1.py\n",
        "\n",
        "data_preprocessing1.py - python-скрипт, который выполняет выбор определенных нами столбцов и сохранение модицифицированного датасета"
      ],
      "metadata": {
        "id": "usb83uwYSroD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Загрузка датасета\n",
        "df = pd.read_csv('datasets_storage/data.csv')\n",
        "\n",
        "# Выбор необходимых столбцов\n",
        "df = df[['price', 'delivery_time', 'number_of_transit_nodes','departure_city']]\n",
        "\n",
        "# Сохранение модифицированного датасета\n",
        "df.to_csv('datasets_storage/data_prep1.csv', index=False)"
      ],
      "metadata": {
        "id": "5FHLEyezLtHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Создание файла data_preprocessing2.py\n",
        "\n",
        "data_preprocessing2.py - python-скрипт, который создает новую версию датасета, в котором пропущенные (NaN) значения в поле 'price' будут заполнены средним значением и осуществляет сохранение модицифицированного датасета"
      ],
      "metadata": {
        "id": "D99ho43XRj5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Загрузка датасета\n",
        "df = pd.read_csv('datasets_storage/data_prep1.csv')\n",
        "\n",
        "# Заполнение пропущенных значений в поле \"price\" средним значением\n",
        "mean_price = df['price'].mean()\n",
        "\n",
        "# Модификация датасета\n",
        "df['price'].fillna(mean_price, inplace=True)\n",
        "\n",
        "# Сохранение модифицированного датасета\n",
        "df.to_csv('datasets_storage/data_prep2.csv', index=False)"
      ],
      "metadata": {
        "id": "QbnwzjebSA7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Создание файла data_preprocessing3.py\n",
        "\n",
        "data_preprocessing3.py - python-скрипт, который создает новую версию датасета, в котором пропущенные (NaN) значения в поле 'price' будут заполнены средним значением и осуществляет сохранение модицифицированного датасета"
      ],
      "metadata": {
        "id": "2KU3e69YSmp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Загрузка модифицированного датасета\n",
        "df = pd.read_csv('datasets_storage/data_prep2.csv')\n",
        "\n",
        "# Создание нового признака с использованием one-hot-encoding для поля \"departure_city\"\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False)  # Явно указываем sparse_output=False\n",
        "departure_city_ohe = onehot_encoder.fit_transform(df[['departure_city']])\n",
        "departure_city_ohe_df = pd.DataFrame(departure_city_ohe, columns=onehot_encoder.categories_[0])\n",
        "df = pd.concat([df, departure_city_ohe_df], axis=1)\n",
        "\n",
        "# Сохранение датасета с новым признаком\n",
        "df.to_csv('datasets_storage/data_prep3.csv', index=False)\n"
      ],
      "metadata": {
        "id": "diWkPl4JUCuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Создание файла requirements.txt\n",
        "\n",
        "requirements.txt - файл, содержайщий точные версии всех установленных пакетов, и используемый, чтобы зафиксировать требования окружения.\n"
      ],
      "metadata": {
        "id": "gQwbVDV8oo9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pandas~=2.0.1\n",
        "catboost~=1.2\n",
        "scikit-learn~=1.2.2"
      ],
      "metadata": {
        "id": "jw5frwftorBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}